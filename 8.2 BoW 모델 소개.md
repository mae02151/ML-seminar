## 8.2 BoW 모델 소개

​	**Bow(Bag-of-Word):** 텍스트를 수치 특성 벡터로 표현하는 방식.

BoW모델을 과정은 다음과 같이 정리할 수 있다.

> 1. 전체 문서에 대해 고유한 토큰(tokken), 예로 단어로 이루어진 어휘 사전을 만든다
> 2. 특정 문서에 각 단어가 얼마나 자주 등장하는지 헤아려 문서의 특성 벡터를 만든다.



### 8.2.1 단어를 특성 벡터로 변환

---

사이킷런에 구현된 CountVectorizer 클래스를 사용하면 각각의 문서에 있는 단어 카운트를 기반으로 BoW 모델을 만들 수 있다.

```python
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer

count = CountVectorizer()
docs = np.array([
        'The sun is shining',
        'The weather is sweet',
        'The sun is shining, the weather is sweet, and one and one is two'])
bag = count.fit_transform(docs)
```

 CountVectorizer() class는 문서에 있는 단어를 카운트 한다.

.fit_transform() 메소드를 사용하며 다음 세문장을 희소한 특성 벡터로 변환한다.

```python
print(count.vocabulary_)
```

> ```python
> {'the': 6, 'sun': 4, 'is': 1, 'shining': 3, 'weather': 8, 'sweet': 5, 'and': 0, 'one': 2, 'two': 7}
> ```

어휘 사전의 내용을 보려면 count.vocabulary_를 사용하면 된다. 여기서 각 단어의 옆에있는 번호는 인덱스 값이다. 예로 'and'는 인덱스 값이 0, 'is'는 인덱스값이 1이라는 뜻이다.

어휘 사전에는 이렇게 고유 단어와 정수 인덱스가 mapping된 딕셔너리가 저장되어 있다.



```python
print(bag.toarray())
```

> [[0 1 0 1 1 0 1 0 0] 
>
>  [0 1 0 0 0 1 1 0 1] 
>
>  [2 3 2 1 1 1 2 1 1]]

 bag에는 위에서 fit_transform()을 이용해 특성 벡터로 변환된 값들이 존재한다. 위에서 보았던 인덱스 값과 비교하여 보면 처음 0번째 열은 각 문장에서 'and' 단어의 빈도수이다.  1번째 열은 'is'의 단어 빈도수로 문장에 'is'가 하나씩 있고 마지막 문장에서는 'is'가 3개가 있어 3의 값을 출력하는 것을  알 수 있다.

.toarray()를 사용하면 각 단어의 빈도수를 볼 수 있다.



### 8.2.2 tf-idf를 사용하여 단어 적합성 평가

---

- #### tf-idf

  - 자주 등장하고 유용하지 않는 정보의 단어의 가중치를 낮추기 위한 기법	



 **tf-idf**는 **tf**(단어 빈도)와 **idf**(역문서 빈도(inverse document frequency))의 곱으로 정의된다.
$$
\text{tf-idf(t,d)}=\text{tf(t,d)x idf(t,d)}
$$
 역문서 빈도 **idf(t,d)** 다음과 같이 계산된다.
$$
\text{idf}(t,d) = \text{log}\frac{n_d}{1+\text{df}(d, t)}
$$

- n_d: 전체 문서개수.
- df(d,t): 단어 t가 포함된 문서 d의 개수.
- log는 분모가 작을 때 역문서 빈도갑이 너무 커지지 않게 한다.
- 분모에 1이 더해지는 이유는 한번도 등장하지 않는 단어가 있을 시 분모가 0이 되는것을 방지하기 위해서다.



- #### CountVectorizer

  ```python
  from sklearn.feature_extraction.text import TfidfTransformer
  
  tfidf = TfidfTransformer(use_idf=True, 
                           norm='l2', 
                           smooth_idf=True)
  print(tfidf.fit_transform(count.fit_transform(docs))
        .toarray())
  ```

  > *>>*
  >
  > [[0.   0.43 0.   0.56 0.56 0.   0.43 0.   0.  ] 
  >
  > [0.   0.43 0.   0.   0.   0.56 0.43 0.   0.56] 
  >
  > [0.5  0.45 0.5  0.19 0.19 0.19 0.3  0.25 0.19]]

  

#### TfidfTransformer()의 매개변수

- norm
  - 정규화의 종류를 정하는 매개변수
    - L2: 벡터의 각 원소의 제곱합이 1이 되도록 조절
    - L1: 벡터의 각 원소의 절대값의 합이 1이 되도록 조절
- smooth_idf
  - 만들 때 0으로 나오는 항목에 대해 작은 값을 더해 feature